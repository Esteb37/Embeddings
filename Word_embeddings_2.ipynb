{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ipNDKdjPtvc"
      },
      "source": [
        "### Load GLOVE model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqBso-R0TDSd",
        "outputId": "59b0d314-5c88-462c-ec59-92ed23a45fa5"
      },
      "source": [
        "1) Download model from http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
        "2) Unzip the file\n",
        "3) Obtain glove.42B.300d.txt from the folder\n",
        "4) Place the .txt inside the same folder as this script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_T-3QvanYUV"
      },
      "source": [
        "### Paper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'glove' from 'c:\\\\Users\\\\Esteban\\\\Documents\\\\Embeddings\\\\glove.py'>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib\n",
        "import glove\n",
        "import numpy as np\n",
        "importlib.reload(glove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting model from files...\n",
            "Finished extracting model from files in 155.98961091041565 seconds\n"
          ]
        }
      ],
      "source": [
        "loaded_model = glove.Glove(\"glove.42B.300d.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = glove.Glove(None)\n",
        "\n",
        "model.model = loaded_model.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### One word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YAzymtbLP6co"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.2111  ,  0.21763 , -0.52638 , -0.42277 ,  0.84672 , -0.038383,\n",
              "       -1.9201  , -0.30959 ,  0.021942, -0.49525 ])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(\"cat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### List of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.1110e-01,  2.1763e-01, -5.2638e-01, -4.2277e-01,  8.4672e-01,\n",
              "        -3.8383e-02, -1.9201e+00, -3.0959e-01,  2.1942e-02, -4.9525e-01,\n",
              "         7.7306e-01,  1.6158e-01, -1.9716e-01, -5.7098e-01, -5.3608e-02,\n",
              "         7.0278e-02, -6.0636e-01, -1.2083e-01, -5.7444e-01, -3.7019e-02,\n",
              "         2.6274e-01, -3.3650e-02,  1.2242e-01, -1.4652e-01,  2.6033e-01,\n",
              "        -2.9463e-01,  1.1520e-01,  3.6812e-02,  3.4356e-03, -2.1683e-04,\n",
              "         5.5426e-01, -5.0978e-01,  2.3785e-01,  2.5400e-02, -4.7775e-02,\n",
              "        -4.0466e-01,  2.6140e-01, -3.4749e-01,  3.7919e-01, -1.9430e-01,\n",
              "         7.1057e-02, -6.3590e-01, -1.4570e-01, -2.5429e-03, -2.9784e-01,\n",
              "         3.0019e-01, -5.3580e-01, -8.7513e-02, -2.1339e-02, -1.7687e-01,\n",
              "         1.9113e-01, -3.0737e-01, -5.6812e-01,  4.6192e-01,  1.9877e-01,\n",
              "         2.0665e-01, -9.3993e-02,  2.9382e-01,  3.2730e-01,  5.8050e-02,\n",
              "        -7.3197e-01, -7.7637e-01,  4.3869e-01,  1.8500e-01,  2.3261e-01,\n",
              "         3.5647e-01, -3.6687e-01,  1.2256e-03, -1.2229e+00,  3.6615e-01,\n",
              "        -3.6965e-02,  3.6553e-01,  1.0303e-01,  1.3494e-01, -3.2071e-02,\n",
              "        -3.7704e-01,  1.5676e-01, -6.4954e-02, -1.4425e-01,  4.5540e-01,\n",
              "         6.9572e-01,  1.7424e-01, -1.0686e-01,  5.0207e-01, -4.5237e-01,\n",
              "         1.8477e-01, -1.2709e-01,  6.5327e-01,  2.9422e-02,  1.6903e-01,\n",
              "        -1.3607e-01, -6.6783e-01, -1.5619e-01, -9.7961e-03, -9.2976e-02,\n",
              "        -7.3335e-01, -1.8187e+00,  2.6675e-02,  2.8343e-01, -2.0409e-01,\n",
              "         2.7432e-02, -2.4477e-01,  1.8070e-01,  5.6010e-02, -1.4840e-01,\n",
              "         1.0702e-01, -7.1081e-02,  3.5108e-02, -2.4279e-01, -2.4710e-01,\n",
              "         3.5338e-01, -1.2025e-01,  5.1993e-01, -3.2510e-02, -6.1425e-02,\n",
              "         2.7608e-01, -1.0754e-01, -5.8642e-02, -2.1013e-01, -3.2711e-01,\n",
              "        -5.6485e-01,  5.3328e-02,  8.1460e-01,  8.9608e-01,  5.6984e-01,\n",
              "        -3.6650e-01,  1.8799e-01,  7.1857e-02, -2.4233e-01, -4.0500e-01,\n",
              "        -6.2646e-01, -5.4031e-03,  1.8839e-01, -6.2807e-01, -4.8526e-01,\n",
              "         2.0509e-01,  1.5560e-02, -5.5592e-02, -3.1686e-01,  4.4582e-01,\n",
              "        -7.4506e-01, -2.3464e-01,  3.5697e-01,  2.7672e-01, -3.4658e-02,\n",
              "        -2.9553e-01,  1.0892e-01,  4.9815e-01,  4.5390e-02, -4.1345e-01,\n",
              "         3.3444e-01, -3.2795e-02,  6.3787e-02, -2.6493e-01, -2.6112e-01,\n",
              "        -9.0767e-02,  1.3950e-01, -4.5536e-01,  6.6697e-01,  8.3962e-01,\n",
              "        -5.2895e-02, -1.4638e-01, -4.3999e-01,  5.3076e-01,  8.0568e-02,\n",
              "         1.3796e-01, -1.9015e-01, -2.3527e-01, -1.7632e-01, -1.9680e-01,\n",
              "        -2.2669e-01, -5.5286e-01, -2.1735e-01,  5.5578e-01, -3.7714e-01,\n",
              "        -1.7865e-01,  4.0321e-01, -5.2347e-01, -1.9288e-01, -9.5479e-02,\n",
              "        -4.8039e-01,  2.3991e-02, -8.6424e-02,  1.4968e-01, -1.2867e-01,\n",
              "         3.2547e-01, -4.9989e-01,  1.7529e-01,  3.9106e-01, -1.9364e-01,\n",
              "         5.9090e-02,  3.2595e-02,  2.4663e-01, -3.5267e-01, -2.8403e-01,\n",
              "        -4.7115e-01,  4.8414e-01,  2.0973e-02,  5.9849e-01,  4.3870e-02,\n",
              "         2.1328e-03, -2.0931e-01, -2.0211e-01,  3.8589e-01,  3.9548e-01,\n",
              "         2.3038e-01,  2.4491e-01,  2.7834e-01,  5.6828e-01, -1.4234e-01,\n",
              "         6.7488e-01,  6.4852e-03,  2.9645e-02, -2.8274e-01,  5.3661e-02,\n",
              "        -2.5656e-01, -2.8487e-02, -2.1258e-02, -1.7985e-02,  4.8703e-01,\n",
              "        -3.6394e-01,  1.1476e-01, -2.6886e-01, -2.8556e-01, -2.9508e+00,\n",
              "        -2.5368e-01, -8.7877e-01, -4.1607e-02, -3.0935e-01, -2.7560e-01,\n",
              "         5.7268e-01, -1.1079e-01, -4.3844e-01, -4.4036e-01, -5.8429e-01,\n",
              "         1.8454e-01,  7.7725e-01,  4.9392e-01, -1.0841e-01,  3.2613e-01,\n",
              "         3.5734e-01,  1.8962e-01, -1.3690e-01,  6.7461e-01, -8.1401e-02,\n",
              "         2.4326e-01,  4.0665e-01,  3.2347e-01,  4.0822e-02,  2.2333e-01,\n",
              "        -1.2498e-02,  6.4806e-02,  3.2215e-02, -1.8610e-01,  7.8454e-02,\n",
              "         2.6412e-01, -3.7658e-01,  4.2116e-01,  5.6942e-01, -1.6653e-01,\n",
              "        -1.6693e-01, -3.1635e-01, -1.1354e-01,  1.6122e-01, -3.3425e-01,\n",
              "         5.6519e-01,  3.0971e-01,  2.1785e-01,  3.7175e-01,  4.3842e-01,\n",
              "        -2.8513e-02, -3.6783e-01,  7.2722e-01,  2.1965e-01, -5.1812e-01,\n",
              "         3.3716e-01, -1.6300e-01,  3.4806e-01, -1.2455e-01, -4.6170e-01,\n",
              "         5.8570e-01,  3.4859e-01, -3.4966e-01, -1.3121e-01, -1.6664e-01,\n",
              "        -5.0079e-01,  1.0191e-03,  3.5112e-01,  2.4121e-02, -3.8078e-01,\n",
              "        -1.5757e-01,  1.3171e-01,  6.3291e-01, -3.2111e-01, -4.6260e-02,\n",
              "        -1.7971e-01, -1.3804e-03, -1.5076e-01, -2.4064e-01, -5.1365e-02],\n",
              "       [-3.3575e-01,  3.8897e-01, -4.1929e-01, -3.3219e-01,  5.3170e-01,\n",
              "        -2.5839e-01, -2.3869e+00, -4.3443e-01, -3.9760e-01, -9.9356e-01,\n",
              "         4.7093e-01, -1.6265e-01, -1.3474e-01, -1.3060e+00,  3.4694e-01,\n",
              "         1.2150e-01, -1.5811e-01, -1.1231e-02, -4.6560e-01, -1.8031e-01,\n",
              "         2.6682e-02, -2.8445e-02, -4.4228e-01,  2.0955e-01,  4.4307e-02,\n",
              "         2.7514e-01, -2.3140e-01, -1.0864e-01, -8.7113e-03,  2.0522e-01,\n",
              "         3.6109e-01, -3.5431e-01,  2.5217e-01,  2.6608e-01,  1.1942e-01,\n",
              "        -2.1606e-01,  7.3164e-02,  2.5023e-01,  2.4612e-01,  2.0797e-01,\n",
              "        -1.8702e-01, -3.8054e-02,  2.3604e-01,  4.2484e-01,  1.0187e-01,\n",
              "         5.8443e-02, -6.0782e-01, -5.2279e-01, -2.6276e-02, -1.4402e-01,\n",
              "         2.2169e-01, -1.5850e-01, -8.1178e-01,  8.2893e-02, -2.2136e-02,\n",
              "        -1.2966e-01,  1.7201e-01,  6.2484e-01, -2.3122e-02, -1.5704e-01,\n",
              "        -4.1946e-01, -4.9499e-01,  5.6224e-02, -8.1352e-02,  3.5428e-01,\n",
              "         1.5145e-01, -2.6535e-01,  1.0071e-01, -1.0047e+00,  3.4271e-01,\n",
              "        -3.0790e-03,  3.5994e-01,  4.0070e-01,  1.5180e-01,  1.1983e-01,\n",
              "        -3.0275e-01,  1.3739e-01, -3.6725e-01,  3.6650e-01,  3.1037e-01,\n",
              "         5.1300e-01,  2.0102e-01, -3.4841e-01,  2.8565e-01, -4.8071e-01,\n",
              "         2.1667e-01, -3.7125e-01,  6.0281e-01,  9.9829e-02, -4.7562e-01,\n",
              "        -9.4234e-02, -1.9625e-01, -1.2658e-01,  2.5421e-02, -1.0805e-01,\n",
              "        -9.5298e-01, -2.1365e+00, -2.5989e-01,  2.9010e-01, -1.4846e-01,\n",
              "        -6.3180e-02, -1.6572e-01,  7.3842e-03, -3.0222e-01, -2.8538e-01,\n",
              "         4.7556e-01,  4.1736e-02, -1.5516e-01,  3.9398e-01, -6.0727e-01,\n",
              "         7.8890e-01, -9.2844e-02,  3.2725e-01, -1.9599e-01, -2.1146e-01,\n",
              "         2.3927e-02, -1.7896e-01, -6.5021e-02,  5.2246e-01, -3.8243e-01,\n",
              "        -4.4670e-01,  7.9130e-02,  8.2286e-01,  5.5868e-01,  3.0237e-02,\n",
              "        -3.0010e-01,  4.8222e-01,  5.4899e-01, -3.2240e-01, -6.7086e-01,\n",
              "        -6.1622e-01,  6.6708e-02,  3.0572e-01,  1.5170e-02, -5.2623e-01,\n",
              "         1.5352e-01, -6.6473e-01, -2.0770e-01,  2.5136e-01,  3.6206e-01,\n",
              "        -2.2424e-01,  8.5694e-04,  4.6224e-02, -1.5066e-02, -3.2618e-01,\n",
              "        -9.7696e-02,  2.1966e-02,  2.7861e-01,  1.5840e-01, -2.0210e-01,\n",
              "         7.2365e-02, -1.9570e-01, -2.6862e-01,  1.3854e-01,  4.1905e-02,\n",
              "        -6.3822e-02, -3.2484e-01,  5.5546e-02,  2.8501e-01,  6.7519e-01,\n",
              "         3.0155e-01, -5.0474e-01, -6.7976e-01,  5.1983e-01,  6.5695e-02,\n",
              "         2.5286e-02, -9.6823e-02, -5.2386e-02, -5.7766e-02,  2.1080e-02,\n",
              "        -2.4691e-01, -8.0533e-01, -1.8712e-01,  4.7986e-01, -4.5478e-01,\n",
              "        -7.6232e-02,  6.3681e-01, -4.6249e-01,  2.3123e-01,  7.9812e-02,\n",
              "        -6.1783e-01, -5.4644e-02, -1.5799e-03,  1.4650e-01,  5.3362e-02,\n",
              "        -4.9770e-02, -6.3187e-01, -1.1563e-01,  3.8775e-01,  1.0124e-01,\n",
              "        -3.2881e-03,  1.7987e-01, -6.2480e-02, -2.7772e-01, -4.8288e-01,\n",
              "        -3.7275e-01,  6.1105e-01, -3.2270e-01,  6.9697e-01,  8.8196e-02,\n",
              "         4.4661e-01, -6.5324e-03, -1.0571e-01,  9.4600e-01, -1.9661e-01,\n",
              "        -3.9961e-01,  2.9346e-01,  1.3640e-01,  4.2281e-01, -4.5546e-01,\n",
              "         5.4213e-01, -1.9004e-01,  5.5959e-01, -3.9935e-01,  1.2659e-01,\n",
              "        -2.9526e-01, -1.1524e-01,  1.0132e-01, -1.6572e-01,  3.8628e-01,\n",
              "        -2.5172e-01,  3.0096e-01, -2.2338e-01, -9.3883e-02, -3.1209e+00,\n",
              "         7.9810e-02, -1.1115e+00,  1.6649e-01, -2.3107e-01, -1.2312e-01,\n",
              "         2.0972e-01, -7.0450e-03, -7.3021e-01, -4.7405e-01, -2.8147e-01,\n",
              "         1.0118e-03,  6.6102e-01, -1.1403e-02,  3.1912e-02,  5.0367e-01,\n",
              "         5.1864e-01, -6.0027e-02, -1.5285e-01,  7.3159e-01, -5.5330e-01,\n",
              "        -1.6912e-01, -6.3391e-02,  1.3858e-01,  2.8878e-01,  1.5076e-01,\n",
              "        -2.2552e-01,  2.8992e-01,  5.4796e-01,  1.5510e-01,  5.1603e-01,\n",
              "        -1.9686e-01, -6.4146e-01,  5.0649e-01,  7.0221e-01, -2.1417e-01,\n",
              "         3.5252e-01, -2.9347e-01, -1.9962e-01, -5.5284e-02, -1.0027e-01,\n",
              "         3.3330e-01,  4.9459e-01,  1.7876e-01, -4.1699e-02,  4.6649e-01,\n",
              "        -3.1720e-01, -3.2616e-01,  1.2663e-01, -4.3670e-01, -5.4299e-01,\n",
              "        -1.0077e-01, -2.6449e-01,  1.0524e-01, -3.2500e-01, -2.8024e-01,\n",
              "         4.9458e-01, -2.8948e-03, -8.6985e-01, -8.9116e-02, -2.3145e-01,\n",
              "        -4.0411e-01, -2.3680e-02,  2.4752e-01,  3.2651e-01, -5.3385e-02,\n",
              "        -1.1501e-01, -5.5804e-01,  4.8427e-01,  2.5167e-01, -6.8426e-02,\n",
              "         3.4227e-01,  2.6840e-01, -1.4929e-01, -2.3516e-01,  3.9194e-02],\n",
              "       [-2.5734e-01, -2.0404e-01, -2.1040e-01, -5.0661e-01,  2.4957e-01,\n",
              "        -2.3918e-01, -2.3018e+00, -1.9739e-01,  2.2438e-03, -3.9468e-01,\n",
              "         9.0250e-01, -4.4758e-01, -1.4589e-01, -2.7937e-01,  2.2605e-01,\n",
              "        -2.9183e-01, -3.3600e-01, -5.3768e-01, -2.0243e-01,  2.5019e-01,\n",
              "         1.3393e-01, -6.3730e-01,  9.1077e-03, -6.9793e-01,  3.4235e-01,\n",
              "         4.6521e-01,  2.4239e-02,  1.0780e-01,  4.0640e-01, -1.4167e-01,\n",
              "         5.4200e-01, -5.9060e-02, -3.3914e-01,  1.9435e-01,  1.0871e-01,\n",
              "         2.6484e-01, -8.3715e-02, -7.6245e-02, -1.6798e-01,  2.0501e-01,\n",
              "        -5.4161e-02, -1.0698e-01,  2.1333e-01, -5.4237e-01, -3.8149e-01,\n",
              "         8.8802e-01, -2.9054e-01,  2.7447e-01, -1.7883e-01,  2.4233e-01,\n",
              "        -1.7695e-01,  1.5471e-01, -2.8032e-01,  7.5492e-01, -1.7927e-02,\n",
              "         3.2276e-01, -1.4711e-01, -1.5720e-01, -4.2107e-01,  1.3529e-01,\n",
              "         2.9172e-01, -7.3847e-02, -4.3617e-01,  2.0702e-01, -6.3773e-01,\n",
              "        -1.9453e-02,  7.2500e-02, -1.3104e-01,  3.2509e-02, -4.5923e-01,\n",
              "        -9.6404e-01, -2.9365e-01,  4.6691e-01, -5.9232e-02,  3.0528e-01,\n",
              "         2.2414e-01,  8.3959e-02, -3.3893e-01,  4.2387e-01,  2.7279e-01,\n",
              "        -2.1767e-01,  1.9987e-02,  1.9037e-01,  5.3578e-01, -2.8011e-01,\n",
              "         4.2011e-01, -3.9010e-01, -9.6659e-02,  2.6190e-01, -5.3628e-01,\n",
              "         6.9896e-01, -4.5547e-01,  3.7001e-01, -2.5577e-01, -2.1121e-01,\n",
              "        -8.5306e-01, -1.7389e+00, -6.5624e-01, -2.7564e-01,  1.4518e-02,\n",
              "         1.3040e-01,  6.4130e-01,  2.6551e-01, -1.1149e-01, -5.4092e-01,\n",
              "         1.1691e-01, -6.2281e-02,  2.7659e-01,  2.5001e-01, -1.2133e-01,\n",
              "         3.3996e-01, -4.3425e-01,  3.6733e-01,  8.2764e-02,  5.3541e-02,\n",
              "         2.6526e-01, -5.0298e-01, -5.4868e-01,  2.1784e-01,  8.8729e-02,\n",
              "         4.0434e-01,  1.9209e-02,  2.8484e-02,  2.9547e-01,  2.3810e-01,\n",
              "         4.9535e-01, -3.7138e-01,  3.8478e-01,  4.1554e-01, -1.6575e-01,\n",
              "        -3.7288e-01,  3.1284e-01,  7.1741e-02, -3.9757e-01,  7.2522e-01,\n",
              "        -6.8002e-02,  4.7500e-01, -1.0193e+00,  4.2327e-01,  6.7670e-01,\n",
              "        -6.2211e-01,  6.6711e-01, -3.1731e-02,  9.0290e-02,  4.0514e-01,\n",
              "        -6.4351e-01,  1.3113e-01,  2.5314e-01,  1.1083e+00, -8.7524e-01,\n",
              "        -3.8302e-01, -7.9048e-03, -3.5292e-01,  1.6845e-01, -1.3551e-01,\n",
              "         1.3177e-01, -3.3335e-01, -8.3003e-02,  3.1274e-01,  8.4201e-02,\n",
              "        -8.2780e-02,  3.1993e-02, -6.1147e-01, -1.9557e-03, -2.9313e-01,\n",
              "        -3.3595e-02, -4.2393e-01, -1.4161e-01, -2.2582e-01,  8.4171e-01,\n",
              "        -2.9591e-01, -2.8610e-01, -2.3420e-01,  1.3774e-02, -3.1554e-01,\n",
              "         1.6476e-02, -9.0240e-02, -2.1439e-01, -2.4798e-01, -2.8771e-01,\n",
              "        -1.2560e-01, -4.3941e-01,  9.6667e-02,  7.2804e-02, -7.1676e-02,\n",
              "         5.4044e-01, -1.2258e-01,  7.9429e-01,  2.0544e-01,  8.1429e-02,\n",
              "        -1.2372e-01,  3.2965e-01, -1.9678e-02, -2.4451e-01, -5.9930e-01,\n",
              "        -3.0791e-01,  3.4061e-01, -3.1602e-01, -3.2509e-01, -7.5343e-01,\n",
              "        -9.5728e-02, -3.5135e-01, -3.6012e-01, -3.5143e-01, -2.5918e-01,\n",
              "        -9.9191e-02,  4.3088e-01,  9.3315e-02,  2.6017e-01,  5.6379e-01,\n",
              "        -3.8064e-01,  6.4447e-01,  3.9317e-01, -9.2335e-02,  2.4828e-01,\n",
              "         8.3071e-01, -3.4974e-01, -2.0368e-01, -2.2343e-01,  6.1357e-04,\n",
              "        -3.1420e-01,  6.5958e-01,  3.9349e-01,  6.0193e-03, -2.8533e+00,\n",
              "        -2.3710e-01,  2.5431e-01,  3.1840e-01, -3.8820e-01,  2.3563e-01,\n",
              "         4.3359e-01,  1.8576e-02, -2.8645e-01, -5.0609e-01,  3.5533e-01,\n",
              "        -3.6502e-01,  1.8519e-01,  1.1675e-01, -2.1378e-01,  2.3044e-02,\n",
              "         4.3335e-01,  1.8221e-01, -6.3717e-01, -3.9387e-01, -4.5740e-01,\n",
              "        -7.0239e-02,  4.6305e-01, -1.8641e-01,  4.5431e-01,  4.7442e-01,\n",
              "        -7.0352e-01, -6.6314e-02, -1.6460e-01,  4.9888e-01,  5.8088e-01,\n",
              "         2.7743e-01, -3.7607e-01,  5.4575e-02,  5.9415e-02,  4.0728e-01,\n",
              "        -5.4691e-02, -4.0379e-01,  3.8234e-01, -3.0989e-01, -3.1296e-01,\n",
              "         4.9543e-01,  8.6751e-02,  4.3000e-01, -1.6597e-01,  6.1008e-01,\n",
              "        -1.2635e-01, -3.4553e-01,  8.6741e-01, -1.1999e-01, -5.0206e-02,\n",
              "        -5.7519e-02,  2.1902e-01,  4.6359e-01, -7.3589e-01, -2.2356e-01,\n",
              "         1.0696e+00, -3.1751e-01,  3.9121e-01, -1.6195e-01,  2.7868e-01,\n",
              "         1.3581e-01, -7.0814e-02,  1.6045e-01,  6.5002e-01, -4.1509e-01,\n",
              "         5.8333e-02, -5.7520e-01,  2.0029e-01,  3.3518e-01, -1.5763e-01,\n",
              "        -1.7595e-01, -4.4322e-01,  4.6904e-02,  2.3154e-01,  6.1955e-01]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model([\"cat\", \"dog\", \"fish\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6g_tQ_SFyBF"
      },
      "source": [
        "### Generate vector for each of the ends of the feature vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WdJhkOqBFAQp"
      },
      "outputs": [],
      "source": [
        "small = model.get_end_vector([\"small\", \"little\", \"tiny\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZFEwLWXu2H2"
      },
      "source": [
        "### Vector addition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "AHJLe-bEu6SU"
      },
      "outputs": [],
      "source": [
        "addition = model.add([\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5X2X9cSP_Kj"
      },
      "source": [
        "### Project words onto feature subspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "avrZRttCNgxq"
      },
      "outputs": [],
      "source": [
        "mouse_elephant = model.get_word_projections([\"mouse\", \"elephant\"],[\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnNoRLYDQJBB"
      },
      "source": [
        "### Ranking words along a feature subspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "EGVg80jOQMaU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.15063826148831758, -0.29265949514567985, 0.025165008686550437, 0.3255447459998804]\n",
            "[1 2 0 3]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['ice', 'wind', 'sun', 'fire']"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = [\"sun\",\"ice\",\"wind\",\"fire\"]\n",
        "feature_1 = [\"cold\",\"frozen\"]\n",
        "feature_2 = [\"hot\",\"burning\"]\n",
        "model.order_words_along_feature(words, feature_1, feature_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOiRWDHT6Wtq",
        "outputId": "fdc2e156-12d1-460d-eecf-b790082bf538"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from keras.datasets import mnist\n",
        "from sklearn.datasets import load_iris\n",
        "from numpy import reshape\n",
        "import seaborn as sns\n",
        "import pandas as pd  \n",
        "\n",
        "Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU58wYYQ36t2"
      },
      "source": [
        "### Perform PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzE1dnM7x3Bc"
      },
      "outputs": [],
      "source": [
        "def performPCA(words, n):\n",
        "  # words must be an array of vectors produced with the function GloVe_Model_42B[word]\n",
        "  from sklearn.decomposition import PCA\n",
        "\n",
        "  arrays = np.empty((0, 300), dtype='f')\n",
        "  arrays = np.append(arrays, words, axis=0)\n",
        "\n",
        "  wordsPCA =  PCA(n_components=n).fit_transform(arrays)\n",
        "  \n",
        "  return wordsPCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuTRXSv2zJ-b",
        "outputId": "f90fdcb2-37fc-4b94-fab6-527bc3183491"
      },
      "outputs": [],
      "source": [
        "words_PCA = [GloVe_Model_42B[\"small\"],GloVe_Model_42B[\"tiny\"],GloVe_Model_42B[\"little\"], GloVe_Model_42B[\"huge\"], GloVe_Model_42B[\"big\"], GloVe_Model_42B[\"enormous\"]]\n",
        "palabras = performPCA(words_PCA,2)\n",
        "palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipInpR1v39L0"
      },
      "outputs": [],
      "source": [
        "#from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "#arrays = np.empty((0, 300), dtype='f')\n",
        "\n",
        "\t# adds the vector of the query word\n",
        "#arrays = np.append(arrays, [GloVe_Model_42B[\"mouse\"],GloVe_Model_42B[\"elephant\"],GloVe_Model_42B[\"whale\"], GloVe_Model_42B[\"dog\"], GloVe_Model_42B[\"tiny\"], size], axis=0)\n",
        "\n",
        "#principalComponents =  PCA(n_components=2).fit_transform(arrays)\n",
        "#principalComponents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwPb7sFKsMHN"
      },
      "source": [
        "### Graph vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDDxRhsIrWVG"
      },
      "outputs": [],
      "source": [
        "def graphVectors(wordsPCA, names):\n",
        "  # wordsPCA is the output of performPCA function\n",
        "  # names is an array with the names for the word vectors in the same order as wordsPCA's output.\n",
        "\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "\t\n",
        "  # The data are given as list of lists (2d list)\n",
        "\n",
        "  # Taking transpose\n",
        "  x, y = wordsPCA.T\n",
        "\t  \n",
        "  # plot our list in X,Y coordinates\n",
        "  plt.scatter(x, y)\n",
        "  for i, label in enumerate(names):\n",
        "\t  plt.annotate(label, (x[i], y[i]))\n",
        "\t  \n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "X-C0jzJD42Y1",
        "outputId": "e8fe4644-6fd3-4878-e5d5-9bc91c7d01a9"
      },
      "outputs": [],
      "source": [
        "\n",
        "graphVectors(palabras, [\"small\", \"tiny\", \"little\", \"huge\", \"big\", \"enormous\", \"size\"] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ai0nzPjxn85"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9OZkq84MjLL"
      },
      "source": [
        "# Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1-oFCtcYAdF"
      },
      "source": [
        "### Hot-cold scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nsqqG24MhVP"
      },
      "outputs": [],
      "source": [
        "# Generate vector for each of the ends of the feature vector\n",
        "\n",
        "cold = get_end_vector([\"cold\", \"frozen\", \"icy\"])\n",
        "hot = get_end_vector([\"hot\", \"boiling\", \"burning\"])\n",
        "\n",
        "# Generate list of words to be evaluated\n",
        "\n",
        "words = [\"fire\", \"lava\", \"sun\", \"wood\", \"metal\", \"ice\", \"snow\"]\n",
        "\n",
        "PCA_words = glove(words)\n",
        "\n",
        "# Append both ends of the scale to our list\n",
        "PCA_words.append(cold)\n",
        "PCA_words.append(hot)\n",
        "\n",
        "#Perform PCA on list\n",
        "words_2D = performPCA(PCA_words, 2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m5PcQ2Xh5Np",
        "outputId": "d6f6cd8c-b600-41e6-94ec-04e3c757bc12"
      },
      "outputs": [],
      "source": [
        "type(PCA_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHn0ddPcIOwV"
      },
      "outputs": [],
      "source": [
        "from sympy.abc import x\n",
        "\n",
        "X, Y = words_2D.T\n",
        "\n",
        "#Define coordinates for each end of the scale\n",
        "x_c, y_c = words_2D[7].T\n",
        "x_h, y_h = words_2D[8].T\n",
        "\n",
        "#Data to produce the function\n",
        "m = (y_h - y_c) / (x_h - x_c)\n",
        "b = y_c - (m * x_c)\n",
        "F = (m * x) + b\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMx7hMaL9HIj"
      },
      "source": [
        "Plot function that passes through both ends of the scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0Yd1ZCqc1W5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def plotFunction(F):\n",
        "\n",
        "  X_axis = np.linspace(-5, 5, 100)\n",
        "  Y_axis = np.zeros_like(X_axis)\n",
        "\n",
        "  for i in range(len(X_axis)):\n",
        "\t\n",
        "\tY_axis[i] = F.subs(x, X_axis[i])\n",
        "\n",
        "  return X_axis, Y_axis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1Upz3cN9PQP"
      },
      "source": [
        "Function to return query coordinates evaluated in F. Returns array with evaluated Y's."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p29kt8Zp9SY8"
      },
      "outputs": [],
      "source": [
        "def evaluateWords(words_2D, F):\n",
        "\n",
        "  PCA_words_F = []\n",
        "\n",
        "  for word in words_2D:\n",
        "\tPCA_words_F.append(F.subs(x, word[0]))\n",
        "\n",
        "  return PCA_words_F\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKF7bPT_AMPS",
        "outputId": "5a5eabcf-cca3-4136-bc3b-edd08f7f0f0f"
      },
      "outputs": [],
      "source": [
        "Y_data_F = evaluateWords(words_2D, F)\n",
        "Y_data_F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1LKgotedij6"
      },
      "source": [
        "Plot everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "N5nJKS-gWuP1",
        "outputId": "13134fbe-2332-4729-c93d-90034413dd0f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Plot words from list\n",
        "plt.scatter(X, Y)\n",
        "\n",
        "#Plot labels for words in list\n",
        "for i, label in enumerate(words):\n",
        "\tplt.annotate(label, (X[i], Y[i]))\n",
        "\n",
        "#Plot cold end of the scale\n",
        "plt.scatter(x_c, y_c, color = 'yellow')\n",
        "\n",
        "#Plot hot end of the scale\n",
        "plt.scatter(x_h, y_h, color = 'orange')\n",
        "\n",
        "#Plot line connecting both ends\n",
        "plt.plot([x_c, x_h], [y_c, y_h], color = 'red')\n",
        "\n",
        "\n",
        "#Plot function connecting two points\n",
        "X_data, Y_data = plotFunction(F)\n",
        "plt.plot(X_data, Y_data,  c =\"red\" )\n",
        "\n",
        "#Plot differences between points and scale\n",
        "for i in range(len(words_2D)):\n",
        "  plt.plot([X[i], X[i]], [Y[i], Y_data_F[i]] )\n",
        "\n",
        "plt.savefig('Hot_cold_scale')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6DYnNFziXBR"
      },
      "source": [
        "### Animal size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IftVN0eViZ4M"
      },
      "outputs": [],
      "source": [
        "# Generate vector for each of the ends of the feature vector\n",
        "\n",
        "small = get_end_vector([\"small\", \"tiny\", \"little\"])\n",
        "big = get_end_vector([\"big\", \"huge\", \"large\"])\n",
        "\n",
        "# Generate list of words to be evaluated\n",
        "\n",
        "animals = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\"]\n",
        "PCA_animals = glove(animals)\n",
        "\n",
        "# Append both ends of the scale to our list\n",
        "PCA_animals.append(small)\n",
        "PCA_animals.append(big)\n",
        "\n",
        "#Perform PCA on list\n",
        "animals_2D = performPCA(PCA_animals,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXTBscugiyQi"
      },
      "outputs": [],
      "source": [
        "# Define x's and y's for scatter plot\n",
        "X_animals, Y_animals = animals_2D.T\n",
        "\n",
        "#Define coordinates for each end of the scale\n",
        "x_s, y_s = animals_2D[7].T\n",
        "x_b, y_b = animals_2D[8].T\n",
        "\n",
        "#Data to produce the function\n",
        "m_animals = (y_b - y_s) / (x_b - x_s)\n",
        "b_animals = y_s - (m_animals * x_s)\n",
        "F_animals = (m_animals * x) + b_animals\n",
        "\n",
        "# List of Y coordinates evaluated in F\n",
        "Y_data_F_animals = evaluateWords(animals_2D, F_animals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "FExvrj-3jwkZ",
        "outputId": "4d5b6da0-0059-4492-f259-e75cb10c68ca"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Plot words from list\n",
        "plt.scatter(X_animals, Y_animals)\n",
        "\n",
        "#Plot labels for words in list\n",
        "for i, label in enumerate(animals):\n",
        "\tplt.annotate(label, (X_animals[i], Y_animals[i]))\n",
        "\n",
        "#Plot small end of the scale\n",
        "plt.scatter(x_s, y_s, color = 'yellow')\n",
        "\n",
        "#Plot big end of the scale\n",
        "plt.scatter(x_b, y_b)\n",
        "\n",
        "#Plot line connecting both ends\n",
        "plt.plot([x_s, x_b], [y_s, y_b], color = 'red')\n",
        "\n",
        "\n",
        "#Plot function connecting two points\n",
        "X_data_animals, Y_data_animals = plotFunction(F_animals)\n",
        "plt.plot(X_data_animals, Y_data_animals,  c =\"red\" )\n",
        "\n",
        "#Plot differences between points and scale\n",
        "for i in range(len(animals_2D)):\n",
        "  plt.plot([X_animals[i], X_animals[i]], [Y_animals[i], Y_data_F_animals[i]] )\n",
        "\n",
        "plt.savefig('animal_size_scale.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg3Jgg-alOEu"
      },
      "source": [
        "### Sweet-Sour scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vvs519MlchT"
      },
      "outputs": [],
      "source": [
        "# Generate vector for each of the ends of the feature vector\n",
        "\n",
        "sweet = get_end_vector([\"sweet\", \"sugary\", \"candied\"])\n",
        "sour = get_end_vector([\"acid\", \"tart\", \"bitter\"])\n",
        "\n",
        "# Generate list of words to be evaluated\n",
        "\n",
        "food = [\"sugar\", \"honey\", \"salt\", \"lemon\", \"vinegar\", \"water\", \"milk\"]\n",
        "PCA_food = glove(food)\n",
        "\n",
        "# Append both ends of the scale to our list\n",
        "PCA_food.append(sweet)\n",
        "PCA_food.append(sour)\n",
        "\n",
        "#Perform PCA on list\n",
        "food_2D = performPCA(PCA_food,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pdqns_bnv05"
      },
      "outputs": [],
      "source": [
        "# Define x's and y's for scatter plot\n",
        "X_food, Y_food = food_2D.T\n",
        "\n",
        "#Define coordinates for each end of the scale\n",
        "x_sweet, y_sweet = food_2D[7].T\n",
        "x_sour, y_sour = food_2D[8].T\n",
        "\n",
        "#Data to produce the function\n",
        "m_food = (y_sour - y_sweet) / (x_sour - x_sweet)\n",
        "b_food = y_sweet - (m_food * x_sweet)\n",
        "F_food = (m_food * x) + b_food\n",
        "\n",
        "# List of Y coordinates evaluated in F\n",
        "Y_data_F_food = evaluateWords(food_2D, F_food)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "mAHtKFuWoUWS",
        "outputId": "223ce239-d1dd-453f-c11b-e98ddcd0ea7b"
      },
      "outputs": [],
      "source": [
        "#Plot words from list\n",
        "plt.scatter(X_food, Y_food)\n",
        "\n",
        "#Plot labels for words in list\n",
        "for i, label in enumerate(food):\n",
        "\tplt.annotate(label, (X_food[i], Y_food[i]))\n",
        "\n",
        "#Plot small end of the scale\n",
        "plt.scatter(x_sweet, y_sweet, color = 'yellow')\n",
        "\n",
        "#Plot big end of the scale\n",
        "plt.scatter(x_sour, y_sour)\n",
        "\n",
        "#Plot line connecting both ends\n",
        "plt.plot([x_sweet, x_sour], [y_sweet, y_sour], color = 'red')\n",
        "\n",
        "\n",
        "#Plot function connecting two points\n",
        "X_data_food, Y_data_food = plotFunction(F_food)\n",
        "plt.plot(X_data_food, Y_data_food,  c =\"red\" )\n",
        "\n",
        "#Plot differences between points and scale\n",
        "for i in range(len(food_2D)):\n",
        "  plt.plot([X_food[i], X_food[i]], [Y_food[i], Y_data_F_food[i]] )\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdbT8YaCpPYm"
      },
      "source": [
        "### Justice-Injustice scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUVCyMe7pVAS"
      },
      "outputs": [],
      "source": [
        "# Generate vector for each of the ends of the feature vector\n",
        "\n",
        "justice = get_end_vector([\"justice\", \"equity\", \"legal\"])\n",
        "injustice = get_end_vector([\"injustice\", \"inequity\", \"opression\"])\n",
        "\n",
        "# Generate list of words to be evaluated\n",
        "\n",
        "words_justice = [\"gay\", \"migrant\", \"woman\", \"man\", \"american\", \"transexual\", \"latino\"]\n",
        "PCA_justice = glove(words_justice)\n",
        "\n",
        "# Append both ends of the scale to our list\n",
        "PCA_justice.append(justice)\n",
        "PCA_justice.append(injustice)\n",
        "\n",
        "#Perform PCA on list\n",
        "justice_2D = performPCA(PCA_justice,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_DJKzjvqyNs"
      },
      "outputs": [],
      "source": [
        "# Define x's and y's for scatter plot\n",
        "X_justice, Y_justice = justice_2D.T\n",
        "\n",
        "#Define coordinates for each end of the scale\n",
        "x_justice, y_justice = justice_2D[7].T\n",
        "x_injustice, y_injustice = justice_2D[8].T\n",
        "\n",
        "#Data to produce the function\n",
        "m_justice = (y_injustice - y_justice) / (x_injustice - x_justice)\n",
        "b_justice = y_justice - (m_justice * x_justice)\n",
        "F_justice = (m_justice * x) + b_justice\n",
        "\n",
        "# List of Y coordinates evaluated in F\n",
        "Y_data_F_justice = evaluateWords(justice_2D, F_justice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "VuOcMyjPrxgQ",
        "outputId": "6064a939-c5af-486e-bc27-a88874c870e3"
      },
      "outputs": [],
      "source": [
        "#Adjust size of plot\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "#Plot words from list\n",
        "plt.scatter(X_justice, Y_justice)\n",
        "\n",
        "#Plot labels for words in list\n",
        "for i, label in enumerate(words_justice):\n",
        "\tplt.annotate(label, (X_justice[i], Y_justice[i]))\n",
        "\n",
        "#Plot small end of the scale\n",
        "plt.scatter(x_justice, y_justice, color = 'yellow')\n",
        "\n",
        "#Plot big end of the scale\n",
        "plt.scatter(x_injustice, y_injustice, color = 'orange')\n",
        "\n",
        "#Plot line connecting both ends\n",
        "plt.plot([x_justice, x_injustice], [y_justice, y_injustice], color = 'red')\n",
        "\n",
        "\n",
        "#Plot function connecting two points\n",
        "X_data_justice, Y_data_justice = plotFunction(F_justice)\n",
        "plt.plot(X_data_justice, Y_data_justice,  c =\"red\" )\n",
        "\n",
        "#Plot differences between points and scale\n",
        "for i in range(len(justice_2D)):\n",
        "  plt.plot([X_justice[i], X_justice[i]], [Y_justice[i], Y_data_F_justice[i]] )\n",
        "\n",
        "\n",
        "plt.savefig('justice_injustice_scale.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMW9oP9tTIjE"
      },
      "source": [
        "## Find scale vector from centroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxeKPazlTOou"
      },
      "outputs": [],
      "source": [
        "# 1 Generate end vectors\n",
        "\n",
        "small = glove([\"small\", \"tiny\", \"little\"])\n",
        "big = glove([\"big\", \"huge\", \"large\"])\n",
        "\n",
        "small_2D = performPCA(small, 2)\n",
        "big_2D = performPCA(big, 2)\n",
        "\n",
        "x_s, y_s = small_2D[0].T\n",
        "x_t, y_t = small_2D[1].T\n",
        "x_l, y_l = small_2D[2].T\n",
        "\n",
        "x_b, y_b = small_2D[0].T\n",
        "x_h, y_h = small_2D[1].T\n",
        "x_large, y_large = big_2D[2].T\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT69AxjpceMt",
        "outputId": "5fe9ecf0-88df-4601-d7f8-bc87035e47de"
      },
      "outputs": [],
      "source": [
        "# Find centroid of small end\n",
        "\n",
        "x_avg_small = ((x_s + x_t + x_l) / 3)\n",
        "y_avg_small = ((y_s + y_t + y_l) / 3)\n",
        " \n",
        "small_centroid = [x_avg_small, y_avg_small]\n",
        " \n",
        "small_centroid\n",
        "\n",
        "# Find centroid of big end\n",
        "x_avg_big = ((x_b + x_h + x_large) / 3)\n",
        "y_avg_big = ((y_b + y_h + y_large) / 3)\n",
        " \n",
        "big_centroid = [x_avg_big, y_avg_big]\n",
        " \n",
        "big_centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "HHumZSP6eGMV",
        "outputId": "c53a4b15-8ce5-41a2-fe92-4aa679ade832"
      },
      "outputs": [],
      "source": [
        "#Plot line between centroids\n",
        "\n",
        "x = (small_centroid[0], big_centroid[0])\n",
        "y = (small_centroid[1], big_centroid[1])\n",
        "\n",
        "plt.plot([small_centroid[0], big_centroid[0]], [small_centroid[1], big_centroid[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_dkblT0jwZi"
      },
      "source": [
        "Plot animals alongside SIZE scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Zol3T5rag8Lj",
        "outputId": "3f873f1f-f07b-4131-96ba-b75df9757ddb"
      },
      "outputs": [],
      "source": [
        "animals = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\"]\n",
        "\n",
        "PCA_animals = glove(animals)\n",
        "\n",
        "#Perform PCA on list\n",
        "animals_2D = performPCA(PCA_animals, 2)\n",
        "\n",
        "x, y = animals_2D.T\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.plot([small_centroid[0], big_centroid[0]], [small_centroid[1], big_centroid[1]], color = \"red\")\n",
        "\n",
        "for i, label in enumerate(animals):\n",
        "\tplt.annotate(label, (x[i], y[i]))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "NBImT7i6l1FR",
        "outputId": "7d49653f-0792-4e40-89b5-809d9b9194db"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "animals = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\"]\n",
        "small_feature = get_end_vector([\"small\", \"tiny\", \"little\"])\n",
        "big_feature = get_end_vector([\"big\", \"huge\", \"large\"])\n",
        "\n",
        "\n",
        "PCA_animals = glove(animals)\n",
        "PCA_animals.append(small_feature)\n",
        "PCA_animals.append(big_feature)\n",
        "\n",
        "\n",
        "#Perform PCA on list\n",
        "animals_2D = performPCA(PCA_animals, 2)\n",
        "\n",
        "x, y = animals_2D.T\n",
        "\n",
        "x_s, y_s = animals_2D[7].T\n",
        "x_b, y_b = animals_2D[8].T\n",
        "\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.plot([small_centroid[0], big_centroid[0]], [small_centroid[1], big_centroid[1]], color = \"purple\")\n",
        "for i, label in enumerate(animals):\n",
        "\tplt.annotate(label, (x[i], y[i]))\n",
        "\n",
        "plt.scatter(x_s, y_s)\n",
        "plt.scatter(x_b, y_b)\n",
        "plt.plot([x_s, x_b], [y_s, y_b], color = 'red')\n",
        "\n",
        "plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "z0XSrFPLnuX3",
        "outputId": "343b748b-9c7d-4385-daca-c45a44bb0ab9"
      },
      "outputs": [],
      "source": [
        "animals = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\", \"small\", \"big\"]\n",
        "\n",
        "\n",
        "PCA_animals = glove(animals)\n",
        "\n",
        "\n",
        "#Perform PCA on list\n",
        "animals_2D = performPCA(PCA_animals, 2)\n",
        "\n",
        "x, y = animals_2D.T\n",
        "\n",
        "x_s, y_s = animals_2D[7].T\n",
        "x_b, y_b = animals_2D[8].T\n",
        "\n",
        "\n",
        "plt.scatter(x, y)\n",
        "\n",
        "for i, label in enumerate(animals):\n",
        "\tplt.annotate(label, (x[i], y[i]))\n",
        "\n",
        "plt.scatter(x_s, y_s)\n",
        "plt.scatter(x_b, y_b)\n",
        "plt.plot([x_s, x_b], [y_s, y_b], color = 'red')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_FAwgVg0MFS"
      },
      "source": [
        "https://plotly.com/python/3d-scatter-plots/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "M952w1M6qSQh",
        "outputId": "1f66de57-32b1-42f3-db3c-a485eb5244a5"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "animals = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\", \"small\", \"big\"]\n",
        "\n",
        "\n",
        "PCA_animals = glove(animals)\n",
        "\n",
        "\n",
        "#Perform PCA on list\n",
        "animals_2D = performPCA(PCA_animals, 3)\n",
        "\n",
        "x, y, z = animals_2D.T\n",
        "\n",
        "# Helix equation\n",
        "t = np.linspace(0, 10, 50)\n",
        "\n",
        "\n",
        "data=go.Scatter3d(x=x, y=y, z=z, mode='markers+text', text = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\", \"small\", \"big\"])\n",
        "fig = go.Figure(data = data)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2hjkDeiO8a6"
      },
      "source": [
        "Por hacer:\n",
        "* Lollipops\n",
        "* Sumas\n",
        "* Heat maps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7agP_gFqNWRk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUDgVwaAf55j"
      },
      "source": [
        "# Lollipops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEa3hVYFf48W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Data frame must contain word and its respective value in the scale.\n",
        "# First we need to define the scale vector. For that we are going to use the Generate_feature_vector() function.\n",
        "\n",
        "# Now we need a function that projects words onto feature subspace. \n",
        "\n",
        "words = [\"gay\", \"migrant\", \"woman\", \"man\", \"american\", \"transexual\", \"latino\", \"king\", \"queen\", \"traitor\", \"killer\", \"outsider\", \"heterosexual\", \"lesbian\", \"bisexual\", \"pansexual\"]\n",
        "b =  [\"good\", \"valid\", \"legal\"]\n",
        "a = [\"bad\", \"odd\", \"opression\"] \n",
        "\n",
        "word_rankings = get_scores(words, a , b)\n",
        "\n",
        "words_and_projections = zip(words,word_rankings)\n",
        "\n",
        "# Create a pandas data frame\n",
        "df = pd.DataFrame(words_and_projections, columns = [\"word\", \"score\"])\n",
        "\n",
        "# Sort data frame from lowest to highest\n",
        "ordered_df = df.sort_values(by='score')\n",
        "my_range=range(1,len(df.index)+1)\n",
        "\n",
        "# For vertical plot\n",
        "'''\n",
        "# For vertical plot\n",
        "plt.stem(ordered_df['score'])\n",
        "plt.xticks( my_range, ordered_df['word'])\n",
        "plt.show()\n",
        "'''\n",
        "# For horizontal plot:\n",
        "\n",
        "# The horizontal plot is made using the hline function\n",
        "\n",
        "my_color=np.where(ordered_df['word']=='gay' , 'orange', 'skyblue')\n",
        "my_size=np.where(ordered_df['word']=='gay', 70, 30)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['score'], color=my_color, alpha=0.4)\n",
        "plt.scatter(ordered_df['score'], my_range, color=my_color, s=my_size, alpha=1)\n",
        " \n",
        "# Add titles and axis names\n",
        "plt.yticks(my_range, ordered_df['word'])\n",
        "plt.title(\"Validity scale for different entities\", loc='center')\n",
        "plt.xlabel('validity score')\n",
        "plt.ylabel('entity')\n",
        "\n",
        "# Show the plot\n",
        "plt.savefig('justice_injustice_lollipops')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h1GOApix1DE"
      },
      "source": [
        "# Vector addition projections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W_7_3_i1_pW"
      },
      "source": [
        "### Projection scores for compound words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_IQgdVY16MB"
      },
      "outputs": [],
      "source": [
        "def get_projection_score_sum(u, v):\n",
        "\t\"\"\"\n",
        "\tGet a scalar magnitude of u on v\n",
        "\t\"\"\"\n",
        "\tprojection_score_sum = (np.dot(u, v)/np.dot(v, v))\n",
        "\treturn projection_score_sum\n",
        "\n",
        "def get_scores_sum(words, feature_set_1, feature_set_2):\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tget_scores([\"mouse\", \"elephant\"],[\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])\n",
        "\n",
        "\t\"\"\"\n",
        "\n",
        "\t# get feature subspace\n",
        "\tfeature_vector_sum = get_feature_vector(feature_set_1, feature_set_2)\n",
        "\n",
        "\t# get projection scores\n",
        "\tprojection_scores_sum = [get_projection_score_sum(word, feature_vector_sum) for word in words]\n",
        "\n",
        "\treturn projection_scores_sum\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUSmJVPfDS_W"
      },
      "outputs": [],
      "source": [
        "big = get_end_vector([\"large\", \"big\", \"huge\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "870IRWAMx5pV"
      },
      "outputs": [],
      "source": [
        "big_dog = VectorAddition([\"big\"], [\"dog\"])\n",
        "small_dog = VectorAddition([\"small\"], [\"dog\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPeX6QUe3tyH"
      },
      "outputs": [],
      "source": [
        "words = [\"dog\",\"whale\",\"mouse\"]\n",
        "\n",
        "glove_words = glove(words)\n",
        "\n",
        "# Append both ends of the scale to our list\n",
        "glove_words.append(big_dog)\n",
        "glove_words.append(small_dog)\n",
        "\n",
        "get_scores_sum(glove_words, [\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])\n",
        "\n",
        "word_labels = [\"dog\", \"whale\", \"mouse\", \"big_dog\", \"small_dog\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kda7Ky-ykSjI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def LollipopsWordSum(words, word_label, a, b, title, x_axis):\n",
        "\n",
        "  word_rankings = get_scores_sum(words, a , b)\n",
        "  words_and_projections = zip(word_label,word_rankings)\n",
        "\t\n",
        "  # Create a pandas data frame\n",
        "  df = pd.DataFrame(words_and_projections, columns = [\"word\", \"score\"])\n",
        "\n",
        "  # Sort data frame from lowest to highest\n",
        "  ordered_df = df.sort_values(by='score')\n",
        "  my_range=range(1,len(df.index)+1)\n",
        "\n",
        "  # For vertical plot\n",
        "  '''\n",
        "  # For vertical plot\n",
        "  plt.stem(ordered_df['score'])\n",
        "  plt.xticks( my_range, ordered_df['word'])\n",
        "  plt.show()\n",
        "  '''\n",
        "  # For horizontal plot:\n",
        "\n",
        "  # The horizontal plot is made using the hline function\n",
        "\n",
        "  my_color=np.where(ordered_df['word']=='gay' , 'orange', 'skyblue')\n",
        "  my_size=np.where(ordered_df['word']=='gay', 70, 30)\n",
        "\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.hlines(y=my_range, xmin=0, xmax=ordered_df['score'], color=my_color, alpha=0.4)\n",
        "  plt.scatter(ordered_df['score'], my_range, color=my_color, s=my_size, alpha=1)\n",
        "  \n",
        "  # Add titles and axis names\n",
        "  plt.yticks(my_range, ordered_df['word'])\n",
        "  plt.title(title, loc='center')\n",
        "  plt.xlabel(x_axis)\n",
        "  plt.ylabel('entity')\n",
        "\n",
        "  # Show the plot\n",
        "  plt.savefig('justice_injustice_lollipops')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "2SSvXGNN_hmZ",
        "outputId": "65c2a906-3b00-4838-b0fd-9e02f0382233"
      },
      "outputs": [],
      "source": [
        "LollipopsWordSum(glove_words, word_labels, [\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"], \"animal size\", \"size score\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c2UrXsw7o5SJ",
        "xwPb7sFKsMHN",
        "f5X2X9cSP_Kj",
        "PnNoRLYDQJBB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "059302a9fbb936d8e6e69c04bdabe5df951acad699dbc23f8cdf654e3714fcaf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
