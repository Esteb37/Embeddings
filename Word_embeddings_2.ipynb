{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ipNDKdjPtvc"
      },
      "source": [
        "### Load GLOVE model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqBso-R0TDSd",
        "outputId": "59b0d314-5c88-462c-ec59-92ed23a45fa5"
      },
      "source": [
        "1) Download model from http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
        "2) Unzip the file\n",
        "3) Obtain glove.42B.300d.txt from the folder\n",
        "4) Place the .txt inside the same folder as this script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_T-3QvanYUV"
      },
      "source": [
        "### Paper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'glove' from 'c:\\\\Users\\\\Esteban\\\\Documents\\\\Embeddings\\\\glove.py'>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib\n",
        "import glove\n",
        "import numpy as np\n",
        "importlib.reload(glove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file glove.42B.300d.txt\n",
            "Finished processing file glove.42B.300d.txt in 2.4789509812990826 minutes\n"
          ]
        }
      ],
      "source": [
        "model = glove.Glove(\"glove.42B.300d.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(model(\u001b[39m\"\u001b[39m\u001b[39mthe\u001b[39m\u001b[39m\"\u001b[39m))\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahigEGs3P4FP"
      },
      "source": [
        "### Generate feature vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAzymtbLP6co"
      },
      "outputs": [],
      "source": [
        "def get_feature_vector(a, b):\n",
        "\t\"\"\"\n",
        "\ta: list of length n of words on one end of the feature continuum\n",
        "\tb: list of length m of words on the other end of the continuum\n",
        "\n",
        "\texample:\n",
        "\tget_feature_vector([\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])\n",
        "\t\n",
        "\t\"\"\"\n",
        "\n",
        "\t# generate list of GloVe embeddings for each end of continuum\n",
        "\tA = glove(a)\n",
        "\tB = glove(b)\n",
        "\n",
        "\t# generate the n x m possible vector differences (\"lines\") between the two ends\n",
        "\tlines = [] # will be a (n x m, 300) matrix\n",
        "\tfor A_i in A:\n",
        "\t\tfor B_j in B:\n",
        "\t\t\tlines.append(B_j - A_i)\n",
        "\n",
        "\t# generate the average of the n x m differences\n",
        "\tfeature_vector = np.mean(np.array(lines), axis = 0) # shape (300,)\n",
        "\treturn feature_vector\t  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtmBPjvEMH9q"
      },
      "outputs": [],
      "source": [
        "size = get_feature_vector([\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])\n",
        "len(size)\n",
        "size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6g_tQ_SFyBF"
      },
      "source": [
        "### Generate vector for each of the ends of the feature vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdJhkOqBFAQp"
      },
      "outputs": [],
      "source": [
        "def get_end_vector(a):\n",
        "\n",
        "  A = glove(a)\n",
        "\n",
        "  end_vector = np.mean(np.array(A), axis = 0)\n",
        "\n",
        "  return end_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrfAwFquFiZX"
      },
      "outputs": [],
      "source": [
        "small = get_end_vector([\"small\", \"little\", \"tiny\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZFEwLWXu2H2"
      },
      "source": [
        "### Vector addition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHJLe-bEu6SU"
      },
      "outputs": [],
      "source": [
        "def VectorAddition(a, b):\n",
        "  \n",
        "  A = glove(a)\n",
        "  B = glove(b)\n",
        "  c = np.add(A,B)\n",
        "\n",
        "  return c\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5X2X9cSP_Kj"
      },
      "source": [
        "### Project words onto feature subspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1J7FzZPN0aA"
      },
      "outputs": [],
      "source": [
        "def get_orthogonal_projection(u, v):\n",
        "\t\"\"\"\n",
        "\tProject vector u on vector v\n",
        "\t\"\"\"\n",
        "\tprojection = (np.dot(u, v)/np.dot(v, v)) * v\n",
        "\treturn projection\n",
        "\n",
        "def get_word_projections(words, feature_set_1, feature_set_2):\n",
        "\t\"\"\"\n",
        "\tAll params are lists of strings \n",
        "\n",
        "\texample:\n",
        "\tget_word_projection([\"mouse\", \"elephant\"],[\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])\n",
        "\n",
        "\t\"\"\"\n",
        "\t# get GloVe embeddings of words\n",
        "\tword_embeddings = glove(words)\n",
        "\n",
        "\t# get feature subspace\n",
        "\tfeature_vector = get_feature_vector(feature_set_1, feature_set_2)\n",
        "\n",
        "\tword_projections = [get_orthogonal_projection(word, feature_vector) for word in word_embeddings]\n",
        "\n",
        "\treturn word_projections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avrZRttCNgxq"
      },
      "outputs": [],
      "source": [
        "mouse_elephant = get_word_projections([\"mouse\", \"elephant\"],[\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])\n",
        "print(mouse_elephant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnNoRLYDQJBB"
      },
      "source": [
        "### Ranking words along a feature subspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGVg80jOQMaU"
      },
      "outputs": [],
      "source": [
        "def get_projection_score(u, v):\n",
        "\t\"\"\"\n",
        "\tGet a scalar magnitude of u on v\n",
        "\t\"\"\"\n",
        "\tprojection_score = (np.dot(u, v)/np.dot(v, v))\n",
        "\treturn projection_score\n",
        "\n",
        "def get_scores(words, feature_set_1, feature_set_2):\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tget_scores([\"mouse\", \"elephant\"],[\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])\n",
        "\n",
        "\t\"\"\"\n",
        "\t# get GloVe embeddings of words\n",
        "\tword_embeddings = glove(words)\n",
        "\n",
        "\t# get feature subspace\n",
        "\tfeature_vector = get_feature_vector(feature_set_1, feature_set_2)\n",
        "\n",
        "\t# get projection scores\n",
        "\tprojection_scores = [get_projection_score(word, feature_vector) for word in word_embeddings]\n",
        "\n",
        "\treturn projection_scores\n",
        "\n",
        "def get_rankings(words, feature_set_1, feature_set_2):\n",
        "\t\"\"\"\n",
        "\tAll params are lists of strings \n",
        "\n",
        "\tRanks words on an axis from feature 1 to feature 2\n",
        "\n",
        "\texample:\n",
        "\tget_rankings([\"mouse\", \"elephant\"],[\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])\n",
        "\n",
        "\t\"\"\"\n",
        "\t# get projection scores\n",
        "\tprojection_scores = get_scores(words, feature_set_1, feature_set_2)\n",
        "\n",
        "\t# order the words by rank\n",
        "\tranks = np.argsort(projection_scores)\n",
        "\n",
        "\treturn ranks\n",
        "\n",
        "def order_words_along_feature(words, feature_set_1, feature_set_2):\n",
        "\t\"\"\"\n",
        "\tReturn a list of words ordered along feature axis\n",
        "\t\"\"\"\n",
        "\tranks = get_rankings(words, feature_set_1, feature_set_2)\n",
        "\treturn list(np.array(words)[ranks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5bDEwe0UHua",
        "outputId": "4a49ae28-e291-4da7-d7a5-477395003b81"
      },
      "outputs": [],
      "source": [
        "get_scores([\"sugar\", \"honey\", \"caramel\",\"cheese\",\"lemon\",\"vinegar\",\"milk\",\"water\",\"sweet\",\"sour\"],[\"sweet\", \"sugary\", \"candied\"], [\"sour\", \"acidic\", \"bitter\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuX3TNoEQX26",
        "outputId": "3f3dc513-3889-4776-c410-dcec723b0c36"
      },
      "outputs": [],
      "source": [
        "# example\n",
        "words = [\"mouse\", \"elephant\", \"whale\", \"ant\"]\n",
        "feature_1 = [\"small\", \"little\", \"tiny\"]\n",
        "feature_2 = [\"large\", \"big\", \"huge\"]\n",
        "order_words_along_feature(words, feature_1, feature_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2M4Ms5BuB23"
      },
      "outputs": [],
      "source": [
        "glove(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-V0XROvXVWX"
      },
      "outputs": [],
      "source": [
        "embeddings =glove(('elephant', 'mouse'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOiRWDHT6Wtq",
        "outputId": "fdc2e156-12d1-460d-eecf-b790082bf538"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from keras.datasets import mnist\n",
        "from sklearn.datasets import load_iris\n",
        "from numpy import reshape\n",
        "import seaborn as sns\n",
        "import pandas as pd  \n",
        "\n",
        "Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU58wYYQ36t2"
      },
      "source": [
        "### Perform PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzE1dnM7x3Bc"
      },
      "outputs": [],
      "source": [
        "def performPCA(words, n):\n",
        "  # words must be an array of vectors produced with the function GloVe_Model_42B[word]\n",
        "  from sklearn.decomposition import PCA\n",
        "\n",
        "  arrays = np.empty((0, 300), dtype='f')\n",
        "  arrays = np.append(arrays, words, axis=0)\n",
        "\n",
        "  wordsPCA =  PCA(n_components=n).fit_transform(arrays)\n",
        "  \n",
        "  return wordsPCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuTRXSv2zJ-b",
        "outputId": "f90fdcb2-37fc-4b94-fab6-527bc3183491"
      },
      "outputs": [],
      "source": [
        "words_PCA = [GloVe_Model_42B[\"small\"],GloVe_Model_42B[\"tiny\"],GloVe_Model_42B[\"little\"], GloVe_Model_42B[\"huge\"], GloVe_Model_42B[\"big\"], GloVe_Model_42B[\"enormous\"]]\n",
        "palabras = performPCA(words_PCA,2)\n",
        "palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipInpR1v39L0"
      },
      "outputs": [],
      "source": [
        "#from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "#arrays = np.empty((0, 300), dtype='f')\n",
        "\n",
        "\t# adds the vector of the query word\n",
        "#arrays = np.append(arrays, [GloVe_Model_42B[\"mouse\"],GloVe_Model_42B[\"elephant\"],GloVe_Model_42B[\"whale\"], GloVe_Model_42B[\"dog\"], GloVe_Model_42B[\"tiny\"], size], axis=0)\n",
        "\n",
        "#principalComponents =  PCA(n_components=2).fit_transform(arrays)\n",
        "#principalComponents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwPb7sFKsMHN"
      },
      "source": [
        "### Graph vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDDxRhsIrWVG"
      },
      "outputs": [],
      "source": [
        "def graphVectors(wordsPCA, names):\n",
        "  # wordsPCA is the output of performPCA function\n",
        "  # names is an array with the names for the word vectors in the same order as wordsPCA's output.\n",
        "\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "\t\n",
        "  # The data are given as list of lists (2d list)\n",
        "\n",
        "  # Taking transpose\n",
        "  x, y = wordsPCA.T\n",
        "\t  \n",
        "  # plot our list in X,Y coordinates\n",
        "  plt.scatter(x, y)\n",
        "  for i, label in enumerate(names):\n",
        "\t  plt.annotate(label, (x[i], y[i]))\n",
        "\t  \n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "X-C0jzJD42Y1",
        "outputId": "e8fe4644-6fd3-4878-e5d5-9bc91c7d01a9"
      },
      "outputs": [],
      "source": [
        "\n",
        "graphVectors(palabras, [\"small\", \"tiny\", \"little\", \"huge\", \"big\", \"enormous\", \"size\"] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ai0nzPjxn85"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9OZkq84MjLL"
      },
      "source": [
        "# Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1-oFCtcYAdF"
      },
      "source": [
        "### Hot-cold scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nsqqG24MhVP"
      },
      "outputs": [],
      "source": [
        "# Generate vector for each of the ends of the feature vector\n",
        "\n",
        "cold = get_end_vector([\"cold\", \"frozen\", \"icy\"])\n",
        "hot = get_end_vector([\"hot\", \"boiling\", \"burning\"])\n",
        "\n",
        "# Generate list of words to be evaluated\n",
        "\n",
        "words = [\"fire\", \"lava\", \"sun\", \"wood\", \"metal\", \"ice\", \"snow\"]\n",
        "\n",
        "PCA_words = glove(words)\n",
        "\n",
        "# Append both ends of the scale to our list\n",
        "PCA_words.append(cold)\n",
        "PCA_words.append(hot)\n",
        "\n",
        "#Perform PCA on list\n",
        "words_2D = performPCA(PCA_words, 2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m5PcQ2Xh5Np",
        "outputId": "d6f6cd8c-b600-41e6-94ec-04e3c757bc12"
      },
      "outputs": [],
      "source": [
        "type(PCA_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHn0ddPcIOwV"
      },
      "outputs": [],
      "source": [
        "from sympy.abc import x\n",
        "\n",
        "X, Y = words_2D.T\n",
        "\n",
        "#Define coordinates for each end of the scale\n",
        "x_c, y_c = words_2D[7].T\n",
        "x_h, y_h = words_2D[8].T\n",
        "\n",
        "#Data to produce the function\n",
        "m = (y_h - y_c) / (x_h - x_c)\n",
        "b = y_c - (m * x_c)\n",
        "F = (m * x) + b\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMx7hMaL9HIj"
      },
      "source": [
        "Plot function that passes through both ends of the scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0Yd1ZCqc1W5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def plotFunction(F):\n",
        "\n",
        "  X_axis = np.linspace(-5, 5, 100)\n",
        "  Y_axis = np.zeros_like(X_axis)\n",
        "\n",
        "  for i in range(len(X_axis)):\n",
        "\t\n",
        "\tY_axis[i] = F.subs(x, X_axis[i])\n",
        "\n",
        "  return X_axis, Y_axis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1Upz3cN9PQP"
      },
      "source": [
        "Function to return query coordinates evaluated in F. Returns array with evaluated Y's."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p29kt8Zp9SY8"
      },
      "outputs": [],
      "source": [
        "def evaluateWords(words_2D, F):\n",
        "\n",
        "  PCA_words_F = []\n",
        "\n",
        "  for word in words_2D:\n",
        "\tPCA_words_F.append(F.subs(x, word[0]))\n",
        "\n",
        "  return PCA_words_F\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKF7bPT_AMPS",
        "outputId": "5a5eabcf-cca3-4136-bc3b-edd08f7f0f0f"
      },
      "outputs": [],
      "source": [
        "Y_data_F = evaluateWords(words_2D, F)\n",
        "Y_data_F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1LKgotedij6"
      },
      "source": [
        "Plot everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "N5nJKS-gWuP1",
        "outputId": "13134fbe-2332-4729-c93d-90034413dd0f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Plot words from list\n",
        "plt.scatter(X, Y)\n",
        "\n",
        "#Plot labels for words in list\n",
        "for i, label in enumerate(words):\n",
        "\tplt.annotate(label, (X[i], Y[i]))\n",
        "\n",
        "#Plot cold end of the scale\n",
        "plt.scatter(x_c, y_c, color = 'yellow')\n",
        "\n",
        "#Plot hot end of the scale\n",
        "plt.scatter(x_h, y_h, color = 'orange')\n",
        "\n",
        "#Plot line connecting both ends\n",
        "plt.plot([x_c, x_h], [y_c, y_h], color = 'red')\n",
        "\n",
        "\n",
        "#Plot function connecting two points\n",
        "X_data, Y_data = plotFunction(F)\n",
        "plt.plot(X_data, Y_data,  c =\"red\" )\n",
        "\n",
        "#Plot differences between points and scale\n",
        "for i in range(len(words_2D)):\n",
        "  plt.plot([X[i], X[i]], [Y[i], Y_data_F[i]] )\n",
        "\n",
        "plt.savefig('Hot_cold_scale')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6DYnNFziXBR"
      },
      "source": [
        "### Animal size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IftVN0eViZ4M"
      },
      "outputs": [],
      "source": [
        "# Generate vector for each of the ends of the feature vector\n",
        "\n",
        "small = get_end_vector([\"small\", \"tiny\", \"little\"])\n",
        "big = get_end_vector([\"big\", \"huge\", \"large\"])\n",
        "\n",
        "# Generate list of words to be evaluated\n",
        "\n",
        "animals = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\"]\n",
        "PCA_animals = glove(animals)\n",
        "\n",
        "# Append both ends of the scale to our list\n",
        "PCA_animals.append(small)\n",
        "PCA_animals.append(big)\n",
        "\n",
        "#Perform PCA on list\n",
        "animals_2D = performPCA(PCA_animals,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXTBscugiyQi"
      },
      "outputs": [],
      "source": [
        "# Define x's and y's for scatter plot\n",
        "X_animals, Y_animals = animals_2D.T\n",
        "\n",
        "#Define coordinates for each end of the scale\n",
        "x_s, y_s = animals_2D[7].T\n",
        "x_b, y_b = animals_2D[8].T\n",
        "\n",
        "#Data to produce the function\n",
        "m_animals = (y_b - y_s) / (x_b - x_s)\n",
        "b_animals = y_s - (m_animals * x_s)\n",
        "F_animals = (m_animals * x) + b_animals\n",
        "\n",
        "# List of Y coordinates evaluated in F\n",
        "Y_data_F_animals = evaluateWords(animals_2D, F_animals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "FExvrj-3jwkZ",
        "outputId": "4d5b6da0-0059-4492-f259-e75cb10c68ca"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Plot words from list\n",
        "plt.scatter(X_animals, Y_animals)\n",
        "\n",
        "#Plot labels for words in list\n",
        "for i, label in enumerate(animals):\n",
        "\tplt.annotate(label, (X_animals[i], Y_animals[i]))\n",
        "\n",
        "#Plot small end of the scale\n",
        "plt.scatter(x_s, y_s, color = 'yellow')\n",
        "\n",
        "#Plot big end of the scale\n",
        "plt.scatter(x_b, y_b)\n",
        "\n",
        "#Plot line connecting both ends\n",
        "plt.plot([x_s, x_b], [y_s, y_b], color = 'red')\n",
        "\n",
        "\n",
        "#Plot function connecting two points\n",
        "X_data_animals, Y_data_animals = plotFunction(F_animals)\n",
        "plt.plot(X_data_animals, Y_data_animals,  c =\"red\" )\n",
        "\n",
        "#Plot differences between points and scale\n",
        "for i in range(len(animals_2D)):\n",
        "  plt.plot([X_animals[i], X_animals[i]], [Y_animals[i], Y_data_F_animals[i]] )\n",
        "\n",
        "plt.savefig('animal_size_scale.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg3Jgg-alOEu"
      },
      "source": [
        "### Sweet-Sour scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vvs519MlchT"
      },
      "outputs": [],
      "source": [
        "# Generate vector for each of the ends of the feature vector\n",
        "\n",
        "sweet = get_end_vector([\"sweet\", \"sugary\", \"candied\"])\n",
        "sour = get_end_vector([\"acid\", \"tart\", \"bitter\"])\n",
        "\n",
        "# Generate list of words to be evaluated\n",
        "\n",
        "food = [\"sugar\", \"honey\", \"salt\", \"lemon\", \"vinegar\", \"water\", \"milk\"]\n",
        "PCA_food = glove(food)\n",
        "\n",
        "# Append both ends of the scale to our list\n",
        "PCA_food.append(sweet)\n",
        "PCA_food.append(sour)\n",
        "\n",
        "#Perform PCA on list\n",
        "food_2D = performPCA(PCA_food,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pdqns_bnv05"
      },
      "outputs": [],
      "source": [
        "# Define x's and y's for scatter plot\n",
        "X_food, Y_food = food_2D.T\n",
        "\n",
        "#Define coordinates for each end of the scale\n",
        "x_sweet, y_sweet = food_2D[7].T\n",
        "x_sour, y_sour = food_2D[8].T\n",
        "\n",
        "#Data to produce the function\n",
        "m_food = (y_sour - y_sweet) / (x_sour - x_sweet)\n",
        "b_food = y_sweet - (m_food * x_sweet)\n",
        "F_food = (m_food * x) + b_food\n",
        "\n",
        "# List of Y coordinates evaluated in F\n",
        "Y_data_F_food = evaluateWords(food_2D, F_food)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "mAHtKFuWoUWS",
        "outputId": "223ce239-d1dd-453f-c11b-e98ddcd0ea7b"
      },
      "outputs": [],
      "source": [
        "#Plot words from list\n",
        "plt.scatter(X_food, Y_food)\n",
        "\n",
        "#Plot labels for words in list\n",
        "for i, label in enumerate(food):\n",
        "\tplt.annotate(label, (X_food[i], Y_food[i]))\n",
        "\n",
        "#Plot small end of the scale\n",
        "plt.scatter(x_sweet, y_sweet, color = 'yellow')\n",
        "\n",
        "#Plot big end of the scale\n",
        "plt.scatter(x_sour, y_sour)\n",
        "\n",
        "#Plot line connecting both ends\n",
        "plt.plot([x_sweet, x_sour], [y_sweet, y_sour], color = 'red')\n",
        "\n",
        "\n",
        "#Plot function connecting two points\n",
        "X_data_food, Y_data_food = plotFunction(F_food)\n",
        "plt.plot(X_data_food, Y_data_food,  c =\"red\" )\n",
        "\n",
        "#Plot differences between points and scale\n",
        "for i in range(len(food_2D)):\n",
        "  plt.plot([X_food[i], X_food[i]], [Y_food[i], Y_data_F_food[i]] )\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdbT8YaCpPYm"
      },
      "source": [
        "### Justice-Injustice scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUVCyMe7pVAS"
      },
      "outputs": [],
      "source": [
        "# Generate vector for each of the ends of the feature vector\n",
        "\n",
        "justice = get_end_vector([\"justice\", \"equity\", \"legal\"])\n",
        "injustice = get_end_vector([\"injustice\", \"inequity\", \"opression\"])\n",
        "\n",
        "# Generate list of words to be evaluated\n",
        "\n",
        "words_justice = [\"gay\", \"migrant\", \"woman\", \"man\", \"american\", \"transexual\", \"latino\"]\n",
        "PCA_justice = glove(words_justice)\n",
        "\n",
        "# Append both ends of the scale to our list\n",
        "PCA_justice.append(justice)\n",
        "PCA_justice.append(injustice)\n",
        "\n",
        "#Perform PCA on list\n",
        "justice_2D = performPCA(PCA_justice,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_DJKzjvqyNs"
      },
      "outputs": [],
      "source": [
        "# Define x's and y's for scatter plot\n",
        "X_justice, Y_justice = justice_2D.T\n",
        "\n",
        "#Define coordinates for each end of the scale\n",
        "x_justice, y_justice = justice_2D[7].T\n",
        "x_injustice, y_injustice = justice_2D[8].T\n",
        "\n",
        "#Data to produce the function\n",
        "m_justice = (y_injustice - y_justice) / (x_injustice - x_justice)\n",
        "b_justice = y_justice - (m_justice * x_justice)\n",
        "F_justice = (m_justice * x) + b_justice\n",
        "\n",
        "# List of Y coordinates evaluated in F\n",
        "Y_data_F_justice = evaluateWords(justice_2D, F_justice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "VuOcMyjPrxgQ",
        "outputId": "6064a939-c5af-486e-bc27-a88874c870e3"
      },
      "outputs": [],
      "source": [
        "#Adjust size of plot\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "#Plot words from list\n",
        "plt.scatter(X_justice, Y_justice)\n",
        "\n",
        "#Plot labels for words in list\n",
        "for i, label in enumerate(words_justice):\n",
        "\tplt.annotate(label, (X_justice[i], Y_justice[i]))\n",
        "\n",
        "#Plot small end of the scale\n",
        "plt.scatter(x_justice, y_justice, color = 'yellow')\n",
        "\n",
        "#Plot big end of the scale\n",
        "plt.scatter(x_injustice, y_injustice, color = 'orange')\n",
        "\n",
        "#Plot line connecting both ends\n",
        "plt.plot([x_justice, x_injustice], [y_justice, y_injustice], color = 'red')\n",
        "\n",
        "\n",
        "#Plot function connecting two points\n",
        "X_data_justice, Y_data_justice = plotFunction(F_justice)\n",
        "plt.plot(X_data_justice, Y_data_justice,  c =\"red\" )\n",
        "\n",
        "#Plot differences between points and scale\n",
        "for i in range(len(justice_2D)):\n",
        "  plt.plot([X_justice[i], X_justice[i]], [Y_justice[i], Y_data_F_justice[i]] )\n",
        "\n",
        "\n",
        "plt.savefig('justice_injustice_scale.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMW9oP9tTIjE"
      },
      "source": [
        "## Find scale vector from centroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxeKPazlTOou"
      },
      "outputs": [],
      "source": [
        "# 1 Generate end vectors\n",
        "\n",
        "small = glove([\"small\", \"tiny\", \"little\"])\n",
        "big = glove([\"big\", \"huge\", \"large\"])\n",
        "\n",
        "small_2D = performPCA(small, 2)\n",
        "big_2D = performPCA(big, 2)\n",
        "\n",
        "x_s, y_s = small_2D[0].T\n",
        "x_t, y_t = small_2D[1].T\n",
        "x_l, y_l = small_2D[2].T\n",
        "\n",
        "x_b, y_b = small_2D[0].T\n",
        "x_h, y_h = small_2D[1].T\n",
        "x_large, y_large = big_2D[2].T\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT69AxjpceMt",
        "outputId": "5fe9ecf0-88df-4601-d7f8-bc87035e47de"
      },
      "outputs": [],
      "source": [
        "# Find centroid of small end\n",
        "\n",
        "x_avg_small = ((x_s + x_t + x_l) / 3)\n",
        "y_avg_small = ((y_s + y_t + y_l) / 3)\n",
        " \n",
        "small_centroid = [x_avg_small, y_avg_small]\n",
        " \n",
        "small_centroid\n",
        "\n",
        "# Find centroid of big end\n",
        "x_avg_big = ((x_b + x_h + x_large) / 3)\n",
        "y_avg_big = ((y_b + y_h + y_large) / 3)\n",
        " \n",
        "big_centroid = [x_avg_big, y_avg_big]\n",
        " \n",
        "big_centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "HHumZSP6eGMV",
        "outputId": "c53a4b15-8ce5-41a2-fe92-4aa679ade832"
      },
      "outputs": [],
      "source": [
        "#Plot line between centroids\n",
        "\n",
        "x = (small_centroid[0], big_centroid[0])\n",
        "y = (small_centroid[1], big_centroid[1])\n",
        "\n",
        "plt.plot([small_centroid[0], big_centroid[0]], [small_centroid[1], big_centroid[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_dkblT0jwZi"
      },
      "source": [
        "Plot animals alongside SIZE scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Zol3T5rag8Lj",
        "outputId": "3f873f1f-f07b-4131-96ba-b75df9757ddb"
      },
      "outputs": [],
      "source": [
        "animals = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\"]\n",
        "\n",
        "PCA_animals = glove(animals)\n",
        "\n",
        "#Perform PCA on list\n",
        "animals_2D = performPCA(PCA_animals, 2)\n",
        "\n",
        "x, y = animals_2D.T\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.plot([small_centroid[0], big_centroid[0]], [small_centroid[1], big_centroid[1]], color = \"red\")\n",
        "\n",
        "for i, label in enumerate(animals):\n",
        "\tplt.annotate(label, (x[i], y[i]))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "NBImT7i6l1FR",
        "outputId": "7d49653f-0792-4e40-89b5-809d9b9194db"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "animals = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\"]\n",
        "small_feature = get_end_vector([\"small\", \"tiny\", \"little\"])\n",
        "big_feature = get_end_vector([\"big\", \"huge\", \"large\"])\n",
        "\n",
        "\n",
        "PCA_animals = glove(animals)\n",
        "PCA_animals.append(small_feature)\n",
        "PCA_animals.append(big_feature)\n",
        "\n",
        "\n",
        "#Perform PCA on list\n",
        "animals_2D = performPCA(PCA_animals, 2)\n",
        "\n",
        "x, y = animals_2D.T\n",
        "\n",
        "x_s, y_s = animals_2D[7].T\n",
        "x_b, y_b = animals_2D[8].T\n",
        "\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.plot([small_centroid[0], big_centroid[0]], [small_centroid[1], big_centroid[1]], color = \"purple\")\n",
        "for i, label in enumerate(animals):\n",
        "\tplt.annotate(label, (x[i], y[i]))\n",
        "\n",
        "plt.scatter(x_s, y_s)\n",
        "plt.scatter(x_b, y_b)\n",
        "plt.plot([x_s, x_b], [y_s, y_b], color = 'red')\n",
        "\n",
        "plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "z0XSrFPLnuX3",
        "outputId": "343b748b-9c7d-4385-daca-c45a44bb0ab9"
      },
      "outputs": [],
      "source": [
        "animals = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\", \"small\", \"big\"]\n",
        "\n",
        "\n",
        "PCA_animals = glove(animals)\n",
        "\n",
        "\n",
        "#Perform PCA on list\n",
        "animals_2D = performPCA(PCA_animals, 2)\n",
        "\n",
        "x, y = animals_2D.T\n",
        "\n",
        "x_s, y_s = animals_2D[7].T\n",
        "x_b, y_b = animals_2D[8].T\n",
        "\n",
        "\n",
        "plt.scatter(x, y)\n",
        "\n",
        "for i, label in enumerate(animals):\n",
        "\tplt.annotate(label, (x[i], y[i]))\n",
        "\n",
        "plt.scatter(x_s, y_s)\n",
        "plt.scatter(x_b, y_b)\n",
        "plt.plot([x_s, x_b], [y_s, y_b], color = 'red')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_FAwgVg0MFS"
      },
      "source": [
        "https://plotly.com/python/3d-scatter-plots/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "M952w1M6qSQh",
        "outputId": "1f66de57-32b1-42f3-db3c-a485eb5244a5"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "animals = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\", \"small\", \"big\"]\n",
        "\n",
        "\n",
        "PCA_animals = glove(animals)\n",
        "\n",
        "\n",
        "#Perform PCA on list\n",
        "animals_2D = performPCA(PCA_animals, 3)\n",
        "\n",
        "x, y, z = animals_2D.T\n",
        "\n",
        "# Helix equation\n",
        "t = np.linspace(0, 10, 50)\n",
        "\n",
        "\n",
        "data=go.Scatter3d(x=x, y=y, z=z, mode='markers+text', text = [\"mouse\", \"hamster\", \"ant\", \"dog\", \"rhino\", \"elephant\", \"whale\", \"small\", \"big\"])\n",
        "fig = go.Figure(data = data)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2hjkDeiO8a6"
      },
      "source": [
        "Por hacer:\n",
        "* Lollipops\n",
        "* Sumas\n",
        "* Heat maps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7agP_gFqNWRk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUDgVwaAf55j"
      },
      "source": [
        "# Lollipops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEa3hVYFf48W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Data frame must contain word and its respective value in the scale.\n",
        "# First we need to define the scale vector. For that we are going to use the Generate_feature_vector() function.\n",
        "\n",
        "# Now we need a function that projects words onto feature subspace. \n",
        "\n",
        "words = [\"gay\", \"migrant\", \"woman\", \"man\", \"american\", \"transexual\", \"latino\", \"king\", \"queen\", \"traitor\", \"killer\", \"outsider\", \"heterosexual\", \"lesbian\", \"bisexual\", \"pansexual\"]\n",
        "b =  [\"good\", \"valid\", \"legal\"]\n",
        "a = [\"bad\", \"odd\", \"opression\"] \n",
        "\n",
        "word_rankings = get_scores(words, a , b)\n",
        "\n",
        "words_and_projections = zip(words,word_rankings)\n",
        "\n",
        "# Create a pandas data frame\n",
        "df = pd.DataFrame(words_and_projections, columns = [\"word\", \"score\"])\n",
        "\n",
        "# Sort data frame from lowest to highest\n",
        "ordered_df = df.sort_values(by='score')\n",
        "my_range=range(1,len(df.index)+1)\n",
        "\n",
        "# For vertical plot\n",
        "'''\n",
        "# For vertical plot\n",
        "plt.stem(ordered_df['score'])\n",
        "plt.xticks( my_range, ordered_df['word'])\n",
        "plt.show()\n",
        "'''\n",
        "# For horizontal plot:\n",
        "\n",
        "# The horizontal plot is made using the hline function\n",
        "\n",
        "my_color=np.where(ordered_df['word']=='gay' , 'orange', 'skyblue')\n",
        "my_size=np.where(ordered_df['word']=='gay', 70, 30)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['score'], color=my_color, alpha=0.4)\n",
        "plt.scatter(ordered_df['score'], my_range, color=my_color, s=my_size, alpha=1)\n",
        " \n",
        "# Add titles and axis names\n",
        "plt.yticks(my_range, ordered_df['word'])\n",
        "plt.title(\"Validity scale for different entities\", loc='center')\n",
        "plt.xlabel('validity score')\n",
        "plt.ylabel('entity')\n",
        "\n",
        "# Show the plot\n",
        "plt.savefig('justice_injustice_lollipops')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h1GOApix1DE"
      },
      "source": [
        "# Vector addition projections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W_7_3_i1_pW"
      },
      "source": [
        "### Projection scores for compound words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_IQgdVY16MB"
      },
      "outputs": [],
      "source": [
        "def get_projection_score_sum(u, v):\n",
        "\t\"\"\"\n",
        "\tGet a scalar magnitude of u on v\n",
        "\t\"\"\"\n",
        "\tprojection_score_sum = (np.dot(u, v)/np.dot(v, v))\n",
        "\treturn projection_score_sum\n",
        "\n",
        "def get_scores_sum(words, feature_set_1, feature_set_2):\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tget_scores([\"mouse\", \"elephant\"],[\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])\n",
        "\n",
        "\t\"\"\"\n",
        "\n",
        "\t# get feature subspace\n",
        "\tfeature_vector_sum = get_feature_vector(feature_set_1, feature_set_2)\n",
        "\n",
        "\t# get projection scores\n",
        "\tprojection_scores_sum = [get_projection_score_sum(word, feature_vector_sum) for word in words]\n",
        "\n",
        "\treturn projection_scores_sum\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUSmJVPfDS_W"
      },
      "outputs": [],
      "source": [
        "big = get_end_vector([\"large\", \"big\", \"huge\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "870IRWAMx5pV"
      },
      "outputs": [],
      "source": [
        "big_dog = VectorAddition([\"big\"], [\"dog\"])\n",
        "small_dog = VectorAddition([\"small\"], [\"dog\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPeX6QUe3tyH"
      },
      "outputs": [],
      "source": [
        "words = [\"dog\",\"whale\",\"mouse\"]\n",
        "\n",
        "glove_words = glove(words)\n",
        "\n",
        "# Append both ends of the scale to our list\n",
        "glove_words.append(big_dog)\n",
        "glove_words.append(small_dog)\n",
        "\n",
        "get_scores_sum(glove_words, [\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"])\n",
        "\n",
        "word_labels = [\"dog\", \"whale\", \"mouse\", \"big_dog\", \"small_dog\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kda7Ky-ykSjI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def LollipopsWordSum(words, word_label, a, b, title, x_axis):\n",
        "\n",
        "  word_rankings = get_scores_sum(words, a , b)\n",
        "  words_and_projections = zip(word_label,word_rankings)\n",
        "\t\n",
        "  # Create a pandas data frame\n",
        "  df = pd.DataFrame(words_and_projections, columns = [\"word\", \"score\"])\n",
        "\n",
        "  # Sort data frame from lowest to highest\n",
        "  ordered_df = df.sort_values(by='score')\n",
        "  my_range=range(1,len(df.index)+1)\n",
        "\n",
        "  # For vertical plot\n",
        "  '''\n",
        "  # For vertical plot\n",
        "  plt.stem(ordered_df['score'])\n",
        "  plt.xticks( my_range, ordered_df['word'])\n",
        "  plt.show()\n",
        "  '''\n",
        "  # For horizontal plot:\n",
        "\n",
        "  # The horizontal plot is made using the hline function\n",
        "\n",
        "  my_color=np.where(ordered_df['word']=='gay' , 'orange', 'skyblue')\n",
        "  my_size=np.where(ordered_df['word']=='gay', 70, 30)\n",
        "\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.hlines(y=my_range, xmin=0, xmax=ordered_df['score'], color=my_color, alpha=0.4)\n",
        "  plt.scatter(ordered_df['score'], my_range, color=my_color, s=my_size, alpha=1)\n",
        "  \n",
        "  # Add titles and axis names\n",
        "  plt.yticks(my_range, ordered_df['word'])\n",
        "  plt.title(title, loc='center')\n",
        "  plt.xlabel(x_axis)\n",
        "  plt.ylabel('entity')\n",
        "\n",
        "  # Show the plot\n",
        "  plt.savefig('justice_injustice_lollipops')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "2SSvXGNN_hmZ",
        "outputId": "65c2a906-3b00-4838-b0fd-9e02f0382233"
      },
      "outputs": [],
      "source": [
        "LollipopsWordSum(glove_words, word_labels, [\"small\", \"little\", \"tiny\"], [\"large\", \"big\", \"huge\"], \"animal size\", \"size score\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c2UrXsw7o5SJ",
        "xwPb7sFKsMHN",
        "f5X2X9cSP_Kj",
        "PnNoRLYDQJBB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "059302a9fbb936d8e6e69c04bdabe5df951acad699dbc23f8cdf654e3714fcaf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
